{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import streamlit as st\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Building embedding strings...\n",
      "ðŸ”„ Generating OpenAI embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 377/377 [04:27<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved OpenAI embeddings to 'dataset_openai.npy'\n",
      "âœ… Saved updated catalog to 'dataset_openai.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ðŸ“˜ Generate OpenAI Embeddings for SHL Catalog\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "# Load OpenAI API key\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Load the cleaned catalog\n",
    "csv_path = \"/Users/parakhchaudhary/SHL_Recommendation_System/dataset/dataset_with_minutes.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Helper: Clean and format the time duration field\n",
    "def format_duration(text):\n",
    "    match = re.search(r\"(\\d+)\", str(text))\n",
    "    return f\"Time required: {int(match.group(1))} minutes\" if match else \"\"\n",
    "\n",
    "# Build embedding string with field labels\n",
    "def build_embedding_text(row):\n",
    "    parts = [\n",
    "        f\"Test Name: {row['name']}\",\n",
    "        f\"Test Types: {row['test_type']}\",\n",
    "        f\"Remote: {row['remote_testing']}\",\n",
    "        f\"Adaptive: {row['adaptive_support']}\"\n",
    "    ]\n",
    "    time_str = format_duration(row[\"Assessment Length\"])\n",
    "    if time_str:\n",
    "        parts.append(time_str)\n",
    "    return \" | \".join(parts)\n",
    "\n",
    "print(\"ðŸ”„ Building embedding strings...\")\n",
    "df[\"text_for_embedding\"] = df.apply(build_embedding_text, axis=1)\n",
    "\n",
    "# Generate embeddings with OpenAI\n",
    "embeddings = []\n",
    "print(\"ðŸ”„ Generating OpenAI embeddings...\")\n",
    "\n",
    "for text in tqdm(df[\"text_for_embedding\"].tolist()):\n",
    "    success = False\n",
    "    while not success:\n",
    "        try:\n",
    "            response = client.embeddings.create(\n",
    "                model=\"text-embedding-ada-002\",\n",
    "                input=text\n",
    "            )\n",
    "            embeddings.append(response.data[0].embedding)\n",
    "            success = True\n",
    "        except Exception as e:\n",
    "            print(\"âŒ Error (retrying in 3s):\", e)\n",
    "            time.sleep(3)\n",
    "\n",
    "# Save results\n",
    "np.save(\"dataset_openai.npy\", embeddings)\n",
    "df.to_csv(\"dataset_openai.csv\", index=False)\n",
    "\n",
    "print(\"âœ… Saved OpenAI embeddings to 'dataset_openai.npy'\")\n",
    "print(\"âœ… Saved updated catalog to 'dataset_openai.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Building embedding strings...\n",
      "ðŸ”„ Generating embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:02<00:00,  5.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Embeddings saved to 'shl_embeddings_with_time.npy'\n",
      "âœ… Updated catalog saved to 'shl_catalog_with_time.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # Load the cleaned catalog\n",
    "# df = pd.read_csv(\"/Users/parakhchaudhary/SHL_Recommendation_System/dataset/dataset_with_minutes.csv\")\n",
    "\n",
    "# # Load SentenceTransformer model\n",
    "# model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# # Helper: Clean and format the time duration field\n",
    "# def format_duration(text):\n",
    "#     match = re.search(r\"(\\d+)\", str(text))\n",
    "#     return f\"Time required: {int(match.group(1))} minutes\" if match else \"\"\n",
    "\n",
    "# # Build embedding string with field labels\n",
    "# def build_embedding_text(row):\n",
    "#     parts = [\n",
    "#         f\"Test Name: {row['name']}\",\n",
    "#         f\"Test Types: {row['test_type']}\",\n",
    "#         f\"Remote: {row['remote_testing']}\",\n",
    "#         f\"Adaptive: {row['adaptive_support']}\",\n",
    "#     ]\n",
    "#     time_str = format_duration(row[\"Assessment Length\"])\n",
    "#     if time_str:\n",
    "#         parts.append(time_str)\n",
    "#     return \" | \".join(parts)\n",
    "\n",
    "# # Create embedding input column\n",
    "# print(\"ðŸ”„ Building embedding strings...\")\n",
    "# df[\"text_for_embedding\"] = df.apply(build_embedding_text, axis=1)\n",
    "\n",
    "# # Generate embeddings\n",
    "# print(\"ðŸ”„ Generating embeddings...\")\n",
    "# embeddings = model.encode(df[\"text_for_embedding\"].tolist(), show_progress_bar=True)\n",
    "\n",
    "# # Save embeddings and updated CSV\n",
    "# np.save(\"dataset_final.npy\", embeddings)\n",
    "# df.to_csv(\"dataset_final.csv\", index=False)\n",
    "\n",
    "# print(\"âœ… Embeddings saved to 'shl_embeddings_with_time.npy'\")\n",
    "# print(\"âœ… Updated catalog saved to 'shl_catalog_with_time.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chaenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
